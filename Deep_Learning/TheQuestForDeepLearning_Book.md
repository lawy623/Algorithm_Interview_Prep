# 百面深度学习
## by 诸葛越

---
# 目录
#### [1.卷积神经网络](#1)
#### [2.循环神经网络](#2)
#### [3.图卷积网络](#3)
#### [4.生成模型](#4)
#### [5.生成对抗网络](#5)

---

# <h1 id="1">第一章：卷积神经网络</h1>

## 卷积

> 卷积操作

	· 局部连接：只有一小部分区域进行计算，感受野逐渐增大
	· 权值共享
	· 保持了相同的空间结构，与生物视觉相关
	· Im2Col: 每个k*k拆成一行，一共l*l行，与k*k的卷积相乘，在resize得到l*l的结果。多个channel就拼起来(l*l x k*k * ci) * (k*k * ci * co)
	
> 参数

    · 感受野： Rt = min(Rt-1 + (kt-1)Mul(Si), L), 与之前的都相关
    · 输出尺寸：lo = floor[(li+2p-k) / s] + 1
    · 参数量：ci * co * kw * kh
    · 计算量：参数量乘上滑动次数(li*lo/si*so)
    
## 卷积变种

> 分组卷积

    · 在通道上不是全连接的，一部分通道输出一部分结果。没有了全通道连接效果
    · 分成g个组能减少计算量到1/g（ci,co都1/g，整体g个）。但是参数量并不变
    · 用于移动端设备
    
> 转置卷积

    · 卷积操作本就是矩阵相乘，转置卷积将特征提取变成了特征图上采样
    · 通常用于完全需要获取与原输入同样大小的任务（分割，深度等等）
    
> 空洞卷积

    · 池化操作扩大了感受野，但是丢失了信息
    · 空洞提升了感受野
    
> 可变卷积

    · 加上offset将conv作用的位置改变，不再局限于规则的网格点采样
    · 不在整数位置需要双线性插值
    
## 网络结构发展

> 网络及特点

    · Alexnet：Relu, Dropout, 分组卷积
    · VGG： 3*3卷积， 2*2 pooling，网络更深， batchnorm。小的kernel参数少计算少，垒起来感受野也大
    · GoogleNet：同时用多个尺寸卷积（并行）提取，bottlenet（1*1卷积压缩通道在复原）
    · Inceptionv2/3: 将k*k卷积分解为k*1&1*k降低计算量
    · Resnet：shortcut抑制了梯度消失，层数大量增加
    · ResNext：中间的卷积改为分组卷积，中间通道也增加了些
    · SEnet：对channel做attention
    · Depthwise+Pointwise：全通道的group conv，后接1*1
    
> 基础模块

    · BN：让各层的输入稳定分布，否则影响学习效率；需要有一个beta和gamma保持分布，不然全为（0~1）了，影响非线性表达
    · 瓶颈结构：通过1*1卷积降低了计算量，但达到更好的效果
    · 沙漏结构：多层conv+skip connection，加大感受野，但是减少梯度消失
    · Pooling：非线性，降维，平移不变性
    
# <h2 id="2">第二章：循环神经网络</h2>

> RNN

    · 状态由新输入和隐含状态决定：ht = (Ux + Wht-1 + b)
    · ot = g(Vh + c)
    · loss和梯度都是所有时刻的和。但是后面时刻的loss回传到前面的导数会scale，导致梯度消失（梯度中有一项跟激活函数相关，导数<1)
    · 无法并行计算
    
> TextCNN

    · 用cnn建模序列。输入为n个词*m维特征
    
> Dropout

    · 集成了大量神经网络的baggin，预测时相当于多模型取平均
    · dropout每次改变了网络的结构，使得神经元不会互相依赖
    
> 长期依赖问题

    · 循环重复的结构。向前传播时，小于1的权值会收敛到0，向后也会
    · 普通的神经网络其实也会，但是小一些。shortcut可以缓解
    · rnn的结构加了activation，但是relu在回传时等价与不加，其他函数更会加快消失
    
> LSTM

    · 输入门，遗忘门，输出门。皆由当前输入和上一轮状态控制，控制门的矩阵皆不一样。改变了信息传递的路径
    · 实验中发现遗忘门和输出门影响最大。
    · 多加入了一个细胞单元用于控制content的留存新增
    
> GRU

    · 相比于lstm用一个门控制留存和输出(z & 1-z)
    
> seq2seq

    · 随着时序增长，造成梯度的影响太大。
    · 将所有输入压缩成一个固定的向量，损失太多
    
# <h3 id="3">第三章：图卷积网络</h2>

暂略。等有机会用到学习再补充

# <h4 id="4">第四章：生成模型</h4>
跳过大部分内容，有机会学习到在补充
> 变分自编码器(VAE)

    · 通过样本encode成正态分布的z（latent code），在decode生成样本的预估，使得预估与原样本相似
    · autoencoder(ae)则没有设置latent code。导致必须要有样本才能进行生成
    · AE主要是模仿不是创造，VAE则能创造生成。两个都是对隐空间进行建模
    
# <h5 id="5">第五章：生成对抗网络</h5>

> GAN基本原理

    · 用两个网络进行对抗。D网络（判别器）的目的是让网络分辨出从data和z生成的差别。G生成器的目的则是让D分辨不出来
    · G最小化(log(1-D(G(z)))的结果，D则要最大化log(D(x))，最小化D(G(z))
    · 与vae相比，不需要原样本一一对应构建loss，而是通过D网络约束分布一致

> GAN的问题

    · 生成器固定时，判别器的最优解使得loss为两个分布的JS散度，当两个低维分布不重合时，最优判别器带来的生成器的损失函数为常数，造成梯度消失
    · 实际使用中，收敛性成问题
    
> GAN的具体改进与应用

暂略。等有机会GAN实战的时候再去读读。    