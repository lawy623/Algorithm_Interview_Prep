# 百面深度学习
## by 诸葛越

---
# 目录
#### [1.卷积神经网络](#1)
#### [2.循环神经网络](#2)
#### [3.图卷积网络](#3)
#### [4.生成模型](#4)
#### [5.生成对抗网络](#5)
#### [6.强化学习](#6)
#### [7.元学习](#7)
#### [8.自动化机器学习](#8)
#### [9.计算机视觉](#9)
#### [10.自然语言处理](#10)
#### [11.推荐系统](#11)
#### [12.计算广告](#12)
#### [13.视频处理](#13)
#### [14.计算机听觉](#14)
#### [15.自动驾驶](#15)

---

# <h1 id="1">第一章：卷积神经网络</h1>

## 卷积

> 卷积操作

	· 局部连接：只有一小部分区域进行计算，感受野逐渐增大
	· 权值共享
	· 保持了相同的空间结构，与生物视觉相关
	· Im2Col: 每个k*k拆成一行，一共l*l行，与k*k的卷积相乘，在resize得到l*l的结果。多个channel就拼起来(l*l x k*k * ci) * (k*k * ci * co)
	
> 参数

    · 感受野： Rt = min(Rt-1 + (kt-1)Mul(Si), L), 与之前的都相关
    · 输出尺寸：lo = floor[(li+2p-k) / s] + 1
    · 参数量：ci * co * kw * kh
    · 计算量：参数量乘上滑动次数(li*lo/si*so)
    
## 卷积变种

> 分组卷积

    · 在通道上不是全连接的，一部分通道输出一部分结果。没有了全通道连接效果
    · 分成g个组能减少计算量到1/g（ci,co都1/g，整体g个）。但是参数量并不变
    · 用于移动端设备
    
> 转置卷积

    · 卷积操作本就是矩阵相乘，转置卷积将特征提取变成了特征图上采样
    · 通常用于完全需要获取与原输入同样大小的任务（分割，深度等等）
    
> 空洞卷积

    · 池化操作扩大了感受野，但是丢失了信息
    · 空洞提升了感受野
    
> 可变卷积

    · 加上offset将conv作用的位置改变，不再局限于规则的网格点采样
    · 不在整数位置需要双线性插值
    
## 网络结构发展

> 网络及特点

    · Alexnet：Relu, Dropout, 分组卷积
    · VGG： 3*3卷积， 2*2 pooling，网络更深， batchnorm。小的kernel参数少计算少，垒起来感受野也大
    · GoogleNet：同时用多个尺寸卷积（并行）提取，bottlenet（1*1卷积压缩通道在复原）
    · Inceptionv2/3: 将k*k卷积分解为k*1&1*k降低计算量
    · Resnet：shortcut抑制了梯度消失，层数大量增加
    · ResNext：中间的卷积改为分组卷积，中间通道也增加了些
    · SEnet：对channel做attention
    · Depthwise+Pointwise：全通道的group conv，后接1*1
    
> 基础模块

    · BN：让各层的输入稳定分布，否则影响学习效率；需要有一个beta和gamma保持分布，不然全为（0~1）了，影响非线性表达
    · 瓶颈结构：通过1*1卷积降低了计算量，但达到更好的效果
    · 沙漏结构：多层conv+skip connection，加大感受野，但是减少梯度消失
    · Pooling：非线性，降维，平移不变性
    
> 初始化

    · xavier：输入输出的方差一致
    · he：更适合relu的输出
    
> normalization

    · batch：在C维度上平均
    · layer：在batch维度上平均
    · instance：在batch、C维度上平均
    · group：分成多个group，在C维度上统一
    
> KL散度

    · 相对熵 = 交叉熵 - 信息熵（额外的信息需求）
    
## 优化方法

> 方法及优势

    · BGD：把全部的cost集合起来算grad，计算速度慢，更新慢，但是梯度稳定
    · SGD: 每一个样本都算一次，更新梯度快。但是不稳定
    · MSGD: 每个batch更新一次，介于BGD和SGD之间，容易陷入鞍点
    动量优化：
    · SGD+Momentum：动态保留上一个梯度方向，保证梯度更新方向较稳定，收敛更快
    自适应学习率：
    · Adagrad：根据梯度的积累动态调整学习率（独立每个参数），越大的梯度累计更新的慢。但是最后梯度积累容易导致更新停止
    · Adadelta：相对于adagrad，不用历史的综合，而是用一个动态的衰减梯度平方和，让最后的梯度不会到无限大。实际使用不需要学习率了。
    · RMSprop：形式上和adadelta基本差不多，设定了动态保留率为0.9
    · Adam：既要通过momentum修正梯度的方向，又要结合动态的梯度平方和调整修正的大小。通常收敛较快，效果比较好
    
## 激活函数

> 方法

    · sigmoid: f(x) = 1 / (1+exp(-z)), 导数为f(z)*(1-f(z))
    · tanh: f(x) = (e^x - e^-x) / (e^x + e^-x), 导数为1-f(z)^2
    · 当x非常大或者小时，两个导数都接近于0，造成梯度消失
    
> relu

    · 计算度不复杂，非线性功能好，梯度不容易为0
    · 但是有些时候神经元的负梯度会导致神经元死亡。因此提出leakyrelu等变种
    
## 求导

> 输出层导数

    · 平方差：-(y-a)f`(z)
    · 交叉熵：a-y
    
# <h2 id="2">第二章：循环神经网络</h2>

> RNN

    · 状态由新输入和隐含状态决定：ht = (Ux + Wht-1 + b)
    · ot = g(Vh + c)
    · loss和梯度都是所有时刻的和。但是后面时刻的loss回传到前面的导数会scale，导致梯度消失（梯度中有一项跟激活函数相关，导数<1)
    · 无法并行计算
    
> TextCNN

    · 用cnn建模序列。输入为n个词*m维特征
    
> Dropout

    · 集成了大量神经网络的baggin，预测时相当于多模型取平均
    · dropout每次改变了网络的结构，使得神经元不会互相依赖
    
> 长期依赖问题

    · 循环重复的结构。向前传播时，小于1的权值会收敛到0，向后也会
    · 普通的神经网络其实也会，但是小一些。shortcut可以缓解
    · rnn的结构加了activation，但是relu在回传时等价与不加，其他函数更会加快消失
    
> LSTM

    · 输入门，遗忘门，输出门。皆由当前输入和上一轮状态控制，控制门的矩阵皆不一样。改变了信息传递的路径
    · 实验中发现遗忘门和输出门影响最大。
    · 多加入了一个细胞单元用于控制content的留存新增
    
> GRU

    · 相比于lstm用一个门控制留存和输出(z & 1-z)
    
> seq2seq

    · 随着时序增长，造成梯度的影响太大。
    · 将所有输入压缩成一个固定的向量，损失太多
    
    
# <h3 id="3">第三章：图卷积网络</h2>

暂略。等有机会用到学习再补充

# <h4 id="4">第四章：生成模型</h4>
跳过大部分内容，有机会学习到在补充
> 变分自编码器(VAE)

    · 通过样本encode成正态分布的z（latent code），在decode生成样本的预估，使得预估与原样本相似
    · autoencoder(ae)则没有设置latent code。导致必须要有样本才能进行生成
    · AE主要是模仿不是创造，VAE则能创造生成。两个都是对隐空间进行建模
    
    
# <h5 id="5">第五章：生成对抗网络</h5>

> GAN基本原理

    · 用两个网络进行对抗。D网络（判别器）的目的是让网络分辨出从data和z生成的差别。G生成器的目的则是让D分辨不出来
    · G最小化(log(1-D(G(z)))的结果，D则要最大化log(D(x))，最小化D(G(z))
    · 与vae相比，不需要原样本一一对应构建loss，而是通过D网络约束分布一致

> GAN的问题

    · 生成器固定时，判别器的最优解使得loss为两个分布的JS散度，当两个低维分布不重合时，最优判别器带来的生成器的损失函数为常数，造成梯度消失
    · 实际使用中，收敛性成问题
    
> GAN的具体改进与应用

暂略。等有机会GAN实战的时候再去读读。    

# <h6 id="6">第六章：强化学习</h6>

> 马尔可夫与强化学习

    · 状态集合S + 动作集合A + 状态转移函数P + 奖励函数R
    · 完成动作a，环境s给予强化信号r（考虑当下或者一段时间内），并且触动环境的变化。进入下一阶段
    · 强化学习的目标是累计奖励最大
    
> 有模型与免模型学习

    · 有模型学习需要建模，泛化性不如免模型学习（因为建模的差距）。但是有模型学习在虚拟空间中可以任意想象，不需要等待真实的反馈
    · 有模型学习需要建立状态转移函数和奖励函数，也难具体建模
    
> 时序差分与蒙特卡洛强化

    · 时序差分在最终结果之前就开始学习，比蒙特卡洛更加灵活
    · 蒙特卡洛只有在经历所有完整状态后才整体更新
    
> Q learning

    · 时序差分算法。用Q函数定义不同状态下执行某动作的期望收益（不仅考虑当下，且考虑未来，递归）
    · 需要知道后续状态的奖励，不能再状态函数未知时使用
    · 使用贪心或e贪心算法进行更新Q函数，选出下一阶段最大价值的动作

> sarsa算法

    · 与q learning相似。但是更新的时候没有使用max，不是激进的选取当下最大价值
    
> 深度强化学习与DQN

    · q learning需要查表确定价值函数，是一种策略型方式。但是查表容易造成维度灾难
    · 改成通过网络进行价值函数的模拟。并通过样本更新该网络

# <h7 id="7">第七章：元学习</h7>
暂略。

# <h8 id="8">第八章：自动化机器学习</h8>

> 目标

    · 能在不同的数据集上泛化的自动构建算法模型的方法
    · 不需要人类干预，在有限计算资源下给出最优解
    
> 方法

    · 网格搜索：把参数空间划分为网格，遍历所有网格配置
    · 随机搜索：随机在网格内取点
    · 贝叶斯优化：先采样一些参数，得到结果后更新后验分布，重新采样（有点像EM）
    
## 贝叶斯优化
暂略

## NAS
定义搜索空间（如网络结构，卷积核参数），通过搜索策略设定网络结构并采取一定评估策略

> 搜索策略

    · 与传统的方法一致（如随机，贝叶斯等）
    · 演化算法
    · 通过强化学习
    · 基于梯度（将搜索空间松弛为连续的，通过梯度更新）

> 一次架构搜索

    · 构建超级架构并训练，测试的时候将所有子架构验证并挑选
    · 构建超级架构并不容易，而且有大小的限制无法包涵所有搜索空间，也无法找到最优解
    
# <h9 id="9">第九章：计算机视觉</h9>

## 目标检测
> 指标

    · mAP：当iou大于某阈值时的precision
    · iou：相交面积占union面积的比例
    
> 分类

    · 一阶段通过输入anchor，充分预测，但是正负样例不平衡，计算效率高
    · 两阶段需要先提取再分类，计算效率低，但是精度高
    
> RCNN系列

    · RCNN: selective search用直方图挑选区域，resize统一大小送入cnn提特征，svm分类
    · SPPNet：rcnn送入cnn的大小固定，需要预处理。通过多层固定池化，提取不同输入的固定大小特征。同时优化提取，先全图提取，在区域提取
    · FastRCNN: 使用ROI pooling；同时用fc取代svm
    · FasterRCNN：使用RPN网络提取每个区域的特征（在feature上滑动窗口，选取不同的anchor)
    · RFCN：最后加一层k^2(c+1)的输出卷积层，用于估计每个区域每个class的类别
    
> YOLO系列

    · 每个格子当作anchor，预测offset和类别
    
> SSD系列

    · 相比yolo使用了设定好的anchor
    · 与two stage相比不在判断anchor是否为前景后景，直接输出cls分类
    · 多尺度，不同的feature上用不同的anchor
    
> 小物体检测

    · 特征金字塔，沙漏结构提升多尺度能力，加大感受野提升全局特性
    · 提高小样本的比例，数据增强
    · 更大的输入比例
    
> IOU计算

    · 两个矩阵有overlap的前提是 max(x1_min, x2_min) > min(x1_max, x2_max) && max(y1_min, y2_min) > min(y1_max, y2_max)
    · 因此overlap部分的面积则为 max(0, max(x1_min, x2_min)-min(x1_max, x2_max)) * max(0, max(y1_min, y2_min)-min(y1_max, y2_max))
    · iou则为 overlap / (s1+s2-overlap)

> nms

    · 按照score排序，每次拿第一个最高分的与其他做iou，筛去iou较小的并重复
    
    ```
    orders = scores.argsort()[::-1]
    keep = []
    while(order.size()>0):
        keep.append(order[0])
        iou = iou with 0 and all others
        orders = order[np.where(iou <= thres)]
    ``` 
    
## 图像分割
> 常见设计

    · 池话层：提升感受野
    · 反卷积：恢复输出比例
    · shortcut：连接编解码器，避免反卷积的特征流失。同时保留高分辨率的底层特征
    
> DeepLab

    · v1：空洞卷积，connected CRF后处理
    · v2：提出ASPP，在同一个特征上使用不同大小的卷积并融合
    · v3：加入bn，使用1x1卷积   
    
## OCR
> 方法

    · CRNN：两阶段，先检测框。 卷积层提取特征，分开成特征序列，用lstm提取，再预测标签
    · FOTS: 共享卷积处理图像，一条路检测，roi pooling预测。像maskrcnn
    
## 图像标注
> 指标

    · BLEU：各阶ngram的精度，匹配粒度更大，但是准确性不足
    · METEOR
    · ROUGH
    · CIDEr
    
## 人体姿态
> 2D

    · 自上而下：先检测后输出
    · 自下而上：先全部预测，通过paf绑定同一个sample
    
> 3D

    · 通过2d预测输入进行输出
    
# <h10 id="10">第十章：自然语言处理</h10>

## 语言特征表示
> Word2Vec

    · 相邻词的共现概率，负采样优化
    · 作为其他任务的预训练结果

> 语言模型

    · 评估一句话是否为人类语言的概率，p(w1...wn)
    · 马尔可夫概率计算
    · 深度学习的预训练模型（bert gpt等）
    · ElMo：双向lstm/gpt：单向transformer/bert：双向transformer
    
> Transformer

    · 自注意力：任意距离的词距离缩减为常量
    · 多头：转到不同的空间捕捉语义信息，类似于多个卷积核
    · 位置编码：捕捉位置的影响（正余弦函数，避免值过大的影响）
    · 可并行化处理（与rnn相比）
    · 缩放因子dk避免梯度消失（避免softmax之后0/1差距过大），dk为qk的方差
    · layer norm和fc层
    · Q:当前询问的值，K：序列所有值的key，V当前的价值表示。从询问值查找与其他所有值的相似度（关系），softmax求加权，应用到V的表示上
        
# <h11 id="11">第十一章：推荐系统</h11>
参考Rec_Sys里面的内容

# <h12 id="12">第十二章：计算广告</h12>
参考Rec_Sys里面的内容

# <h13 id="13">第十三章：视频处理</h13>
主要讲的是传输和超分，略过

## 视频理解

> 方法

    · 单流模型：把rgb concat起来，然后用2D conv直接分类。坏处是没有用到很强的时序信息
    · 双流模型：一支算rgb，一支算optical flow，最后在融合。但是没有对其rgb和optical flow之间的像素关系
    · LCRN：用CNN提取每帧特征，然后用LSTM建立时序特征，最后每帧得分平均用来分类。分段后容易丢失动作片段
    · C3D：取几段视频，每段视频取一些帧，叠在一起，用3D conv进行计。但是3d conv计算量大
    · I3D：把3d conv做在rgb和flow的双流上
    · TSN：整段视频拆分K段，每段取几帧，双流网络提特征，最后特征交叉求解。对双流网络的升级
    · TSM：通过CNN求解多帧的特征，然后通过特征图的shuffle进行空间上的聚合
    · Non Local：相当于一个attention，做全局特征的重新聚合
    · slow fast：两分支分别取样，slow取的多，fast取得少，通过不同的网络提特征，中间做特征交叉
    · NextVlad：特征融合的方法，通过fc做特征的加权。有点像senet。
    · TRN：分成多个组别，每个组别均匀取k帧（k=1，2，3...)。用CNN提出特征，用mlp进行聚合

# <h14 id="14">第十四章：计算机听觉</h14>

# <h15 id="15">第十五章：自动驾驶</h15>