# 深度学习推荐系统
## by 王喆

---
# 目录
#### [1.推荐系统简介](#1)
#### [2.前深度学习时代前的推荐系统](#2)
#### [3.深度学习在推荐系统中的应用](#3)
#### [4.embedding技术在推荐系统中的应用](#4)
#### [5.多视角审视推荐系统](#5)
#### [6.推荐系统的工程实现](#6)
#### [7.推荐系统的评估](#7)

---

# <h1 id="1">第一章：推荐系统简介</h1>

### 问题及总结
> 推荐系统在解决什么问题

	用户角度：如何解决信息过载问题，让用户高效获取感兴趣的信息（与搜索系统相对应）
	公司角度：如何更大限度的吸引用户，提升使用时间，提升转化率，从而达到公司商业目标
	两个方向的目标通常来说是一致有共性的。
    
    推荐系统处理的是人(U)在特定场景(C)下与信息(I)之间的关系 -> F(U, C, I)

>  推荐系统基本架构

	数据部分：
		1. "客户端实时数据处理"， "流平台准实时数据处理"， "离线数据处理"
		2. 样本数据供算法使用；数据生成特征；生成系统监控，商业统计数据
	模型部分：
		1. 召回层：高效从海量数据中找到用户感兴趣的
		2. 排序层：通过精排对初筛结果进行排序
		3. 策略层：通过多样性/新鲜性/流行性等指标进行调整
		4. 离线评估与在线a/b test的存在
		5. 离线训练与在线更新

> 深度学习的贡献

	· 对数据的强拟合能力，对特征组合的强挖掘能力
	· 模型的灵活性能适应不同的应用场景和业务数据

---

# <h2 id="2">第二章：前深度学习时代前的推荐系统</h2>

### 协同过滤 CF
> 传统方法的优势

	· 可解释性强
	· 硬件要求低
	· 易于快速训练和部署

> 皮尔森相关系数

	· 对余弦相似度的补充，如果两个向量取值scale不一样，先减去均值(人对所有物品的均值），去除人的评分偏置的影响
	· 也可以减去物品的评分均值，去除物品偏置的影响
	· 含义就是大家对更好的/更坏的判断是一致的
	· 但是似乎相似性未解决真实的评分问题，如(4.1, 4.2 ,4.3)与(0.1, 0.2, 0.3)是强相关的，但是对新物品评分的预测仍需考虑本身的偏置问题。
	即相似性是相对的，但是评分是绝对的。

> *如何用深度学习构建相似性

    · 无监督：类似word2vec的方式，相近的物品特征相似
    · 有监督：采样正负样本进行有监督训练。正负样本可以从用户行为中获得
    
> UserCF的缺点

	1. 互联网场景下，用户数量通常远大于物品数，保存用户相似度信息有极大的存储开销（ O(n^2) )
	2. 用户数据向量往往是稀疏向量，导致低频场景下不太适用（用户本身评价少，就不好评价新的物品）

> UserCF和ItemCF的使用场景

	1. UserCF更适用于新闻推荐，具备社交特性。用于发现热点，而不是总是看到相关的新闻
	2. ItemCF更适用于更稳定一点的推荐场景，如购物/观影。用户总喜欢看到相同类型的推荐
	3. ItemCF倾向于找相同的类型的物品, UserCF倾向于根据人的相似推荐各种不同的东西

> 协同过滤的缺点

	1. 更偏向于热门物品，对稀疏向量的处理不好（热门物品容易对其他的物品相似度高，总是在推荐热门物品）
	2. 无法建模用户特征/物体特征，仅仅用到了用户与物品的交互，泛化性较弱。

### 矩阵分解

使用隐向量建模用户和物品，增加模型的泛化性。

> 如何构建人和物品的隐向量
    
    · 人和物品的共现矩阵为 n x m, 分解为 (n x k) 和 (m x k)两个矩阵相乘的形式， k即为隐向量的长度。
    · k的取值与模型的泛化性+计算开销相关，实际工程中需要平衡
    · 这里的隐向量也只建模了人对物品的评分，没有其他信息
    · 需要求解人对物品的新的评价时，只需要将两个k维向量点积即可
    
> 如何分解矩阵 
    
    · 奇异值分解 （SVD）：用于分解非方形矩阵。
    · M = UZV'. Z为对焦矩阵，记录了奇异值大小
    · 取奇异值最大的k为，分别去UV取前面的k个向量即可
    
> SVD缺陷

    1. SVD要求共现矩阵是稠密的，否则需要对矩阵进行填充
    2. 计算复杂度高达O(mn^2)，不适合互联网的大量数据进行计算
    
> 通过梯度下降获取隐向量

    1. 构建目标函数为用户评分与隐函数点积的差平方，使用梯度下降计算，并且可以加上正则化
    2. min[sum(r_ui - q_i · p_u)^2 + lambda(||q_i||^2 + ||p_u||^2)], 优化的复杂度变为O(mnk)
    3. 正则化目的：使模型权重变小，因此波动性变小，但是损失函数尽可能不受影响
    
> 为什么矩阵分解泛化性好

    · CF算法都是只用了user或者item的向量进行计算，但是矩阵分解是通过优化全局的最优进行的，因为同时用到了用于和物品的信息
    
> 如何消除用户本身对物品打分的偏差

    · 加上偏差系数: r_ui = mu + b_i + b_u + q_i · p_u
    · mu为全局系数，b_i为物品偏差，b_u为用户偏差
    
> 协同过滤的优劣

    · 优势：
        1. 泛化能力强，同时建模了用户物品之间的关联性
        2. 不需要储存O(m^2)或者O(n^2)的向量，只需要O[(m+n)*k]， 降低了一个数量级
        3. 获取的隐向量即为embedding，容易和深度学习相组合
    · 局限性：
        1.并没有加入物品，用户，上下文本身的信息特征，

### 逻辑回归

协同过滤和矩阵分解都是用用户物品矩阵的相似度进行建模，并没有加入别的特征信息。逻辑回归通过将样本进行分类，预测正样本的概率。

> 怎么建模
    
    · 将用户和物品的各种信息当作特征向量x, 与w做点积，进行sigmoid打分(f(x)=1 / (1+e^-(wx+b))).
    · wx的值越大, 得到的概率就越接近1
    
> 如何优化

    · 通过概率建模, p(y|x, w) = (fw(x))^y * (1-fw(x))^(1-y)。sigmoid建模为softmax的二类形式
    · 根据极大似然, 所有样本的概率最大化为Mul(p(y|x,w)) 对所有样本, 取对数并对w求导更新w
    · sigmoid函数求导为 f'(z) = f(z)*(1-f(z))*z
    · 求导的推导可以看这里, https://zhuanlan.zhihu.com/p/46928319. 梯度为(x(fw(x)-y))对所有样本取平均
    
> logit回归优势

    1. 数学假设符合伯努利公式,可以做二分类的假设
    2. 基本形式是各种特征的加权和, 符合人类的认知, 可解释性强
    
> 局限性

    1. 模型太简单, 无法更有效地进行特征融合, 损失了很多有用的信息
    
> 数据处理与实现方式

    · sparse feature通过embedding(hidden=1，相当于一个linear层)得到d1个sparse结果，然后求和
    · dense feature通过一个linear层计算wx，相当于weighted sum of dense feature
    · 两个结果加起来就是所有的feature的weighted sum，可以当作sigmoid之前的输出

## 特征组合
单一的特征无法会造成信息的损失。

> ploy2通过暴力组合特征加入两两之间的特征交叉，缺点为
    
    1. 原本稀疏的x现在变成了更加稀疏的组合xixj
    2. 权重参数从n个升级为n^2个
    
>  FM模型
    
    · 与poly2相比，权重不再是wij，而是两个权重的内积<wi, wj>, 相当于为每个特征学习了隐权重向量，数量从O(n^2) 降到了O(nk)
    · 更好的应对了数据稀疏性问题，因为现在隐函数在任意的样本下都可以学习了
    · 具体算法实现可看 https://www.jianshu.com/p/bb2bce9135e4
    
> FM升级到FFM

    · 引入了特征域感知。每个特征的隐权重向量不是单一个向量，而是一个向量组，当特征与另一个特征相结合时，选取对应的权重向量（有一点像attention）
    · 复杂度提升为O(kn^2), 因为每个特征组里都有n个向量选择
    · 复杂度提升之后最多也只能做2阶交叉
    
> FFM到FwFM

    · 仍然使用FM当中的vivj，但是多加了一个rij的系数，回到了O(nk)次
    
> GBDT+LR

    · 利用GBDT构建特征，再用LR进行CTR估计
    · GBDT: 梯度提升决策树，XGBoost为优化的常用库
    · 将所有决策树叶子节点组成的特征向量组合起来的到最后的特征。
    · 特征组合能力强劲，而且计算量小，但是训练时间长。但是GBDT容易过拟合，并且丢失了数值特征（只有decision判断了）
    · 从此以后特征工程可以单独进行，只要将得到的特征进行分类即可
    
---

# <h3 id="3">第三章：深度学习在推荐系统中的应用</h3>
可以参考https://github.com/shenweichen/DeepCTR-Torch，查看数据的处理以及实现

> 深度学习优势

    · 表达能力更强，更能挖掘数据
    · 模型灵活，容易对业务应用调整
    
> 演化方向
     
    1）改变网络复杂程度
    2) 改变特征交叉方式
    3) 组合模型
    4) FM模型的演化
    5) 注意力机制的应用
    6）序列模型的使用
    7）强化学习的使用
    
## AutoRec
一个自编码器（两层mlp），从m维向量到k维再到m维，用输入监督输出，中间的k维用作降维特征。由于输出损失存在，模型起到泛化作用。模型可以对缺失值进行填补。

加入正则化更好的避免过拟合。

> User-based和Item-based的区别

    · User-Based每个编码了一个用户对所有物品的评分，只需要forward一次用户向量就知道对所有物品的评分了
    · 但是用户向量是稀疏的，影响到了模型效果

# 特征交叉方法的探索

## Deep Crossing

> 方法

    · embedding层将稀疏特征转换为稠密特征（通过fc层，相当于查表）
    · stacking层将所有的特征拼接在一起
    · multi res layer：多层残差网络将特征进行充分的融合
    · scoring层通过softmax求解目标的概率（比如ctr）

> 历史意义

    · 从当时的角度看，充分的进行了特征的混合，没有手动进行特征交叉了（虽然是把特征拼起来，让resnet去做交叉，没有显式交叉）

## NeuralCF
深度学习的协同过滤模型。

> 方法

    · 将用户向量和物品向量通过fc层得到隐向量，并用隐向量点积得到得分，用sample进行优化
    · 将内积用多层神经网络替换进行输出，能让特征更加充分的混合
    · 可以同时将矩阵分解得到的隐向量一起融入进去

> 优劣

    · 更好的做了信息的交叉，更加灵活的进行了模型组合
    · 没有假如其他的context信息等，仍然是矩阵分解的套路

## PNN

> 方法

    · 相比与deep crossing，将stacking层改成了多个特征的组合拼接（内积外积），更早的进行了特征组合
    · PNN的外积池话实际上是使用了avg pooling后进行外积，损失信息
    
> 优劣

    · 使用了更多的特征，并且强调了主动的特征交叉，让模型更容易捕捉
    · 无差别的特征交叉可能容易损失有价值的信息
    
    
## Wide&Deep
Wide是单层模型，具有记忆能力；Deep是多层模型，具有泛化能力。记忆能力指的是看到相关的特征就输出相近似的结果，单层网络有这样的效果。
多层网络由于做了更多的特征组合，更好的泛化了预测。模型开创了不同网络融合的思路。

> 方法

    · 一部分的特征输入wide单层网络，一部分输入deep多层网络。因此如何选择特征输入的位置是关键
    · wide的部分输入的是直接与结果强相关的特征，充分利用网络的记忆能力；deep部分则是把所有的特征都输入，充分的挖掘相关性
    · wide的输入特征使用了交叉积变化，也包含了特征组合
    · 对两个网络实际上使用了不同的优化器，期望wide网络更稀疏，容易部署
    · deep网络可以理解为deep crossing
    
    
> 数据处理与实现方式

    - wide网络（相当于lr）
    · sparse feature通过embedding(hidden=1，相当于一个linear层)得到d1个sparse结果，然后求和
    · dense feature通过一个linear层计算wx，相当于weighted sum of dense feature
    · 两个结果加起来就是所有的feature的weighted sum，可以当作sigmoid之前的输出
    
    - deep网络（相当于deep crossing）
    · 将sparse feature映射成多维。与dense一起拼接起来，整体输入一个多层linear
    
    - 两个网络的logit输出相加，当作最后结果sigmoid的输入。看实现来说最后是没有加bias的
    
    
## Deep&Cross(DCN)

> 方法

    · 用cross网络替代wide网络，提升特征的交互力度。多个交叉层，每个输入都会与原向量x0。
    · Deep网络更新成cross之后，抛弃了原来的多层mlp的结构，更加主动的进行了信息的融合（比如xix0的外积），使cross网络的表达能力更强
    · 相当避免了deep&wide中的人工挑选特征

# 将FM融入网络结构
FM的特征交叉方式是一种高效的特征组合方式。

## FNN

>  要解决的问题
    
    · 隐含层参数量极大，难以收敛（仅有非零特征的权重被更新）
    · FNN将随即初始化的embedding用FM模型训练好的结果进行初始化。具体操作实际上是让隐权重向量v去初始化embedding层的连接权重（而不是结果）
    · 为特征预训练提供了思路
    · 但只是用来初始化，并没有主动加入特征的组合
    
    
## DeepFM

> 方法

    · 用FM替换了deep & wide中的wide网络（fm中实际上有一层linear，再加上两两乘积和），和dcn一致。但是使用的是fm网络进行替换
    · 输入fm和deep网络中的embedding现在是一样的了
    
    
## NFM

> 方法

    · wide网络保持简单linear，将deep网络替换为fm网络
    · 用神经网络将FM的二阶特征交叉替换掉，争取更高阶的特征交叉形式，是对sparse的feature进行特征的交叉
    · 特征交叉池化层。为了求xixj的和，可以用0.5*(sqrt_of_sum - sum_of_sqrt) = 0.5[(x1+..+xn)^2 - (x1^2+...+xn^2)]的和
    
> 与deepFM的区别是

    · deepFM是吧deep网络和fm网络分开，一个学二阶，一个学更高阶，但是deep网络的输入组合不够明显；
    而这里是把deep接在bi-interaction-pool后面（这个层近似FM层但是不求和），把交叉的特征更深入。
    · 有点像更加强的PNN，结构比较类似
    
    
    
# 注意力机制的使用
## AFM

    · 在特征层和输出层之间加上一个注意力网络，将一个权重联系到特征上去作为注意力得分。
    · 将所有的交叉特征结果用softmax得到注意力得分，与交叉特征加权得到新特征。当attention不存在时，即为nfm网络
    
## DIN
基于电商推荐业务设计的模型

> 方法

    · 用户特征（比如浏览的商品）和商品特征有极强的关联性，直接把特征都扔进网络太简单
    · 利用历史浏览商品和推荐商品求出注意力权重，对对应的历史商品特征进行加权
    · 原来的用户商品特征是所有商品embedding的直接求和，现在变成了根据推荐商品的加权和。
    · 注意这里的attention使用在特征组的序列里面。而且key和query必须是同类（比如店铺和店铺，物品和物品；并不需要求物品和店铺之间的att）
    · local attention单元是把（key，query， key-query， key*query）一起输入dnn网络，求出一个得分
    
## DIEN
DIN的升级版，背景完全一致。模拟了用户兴趣的‘进化’过程。序列模型+注意力机制

> 方法

    · attention仅仅是对序列中的重要性打分，并没有考虑序列的先后顺序（感觉可以加pos embed），最近的行为应该比久远的行为有更大的影响力
    · 兴趣抽取层：跟序列时间相关的表示，用GRU进行模拟
    · 兴趣进化层：在这一层结合了商品特征，与序列化的用户商品特征进行attention处理。使用GRU的同时加入了attention（AUGRU）。更新隐向量时加入了att
    · 序列化模型增加了上线负担，需要合理优化
    
## DRN
强化学习的引入

> 强化学习相关

    · 几个组成部分：智能体、状态、环境、反馈、行动
    · 智能体基于状态进行行动并推送到环境中。推送结果引起反馈，并更新智能体
    · 是一种在线学习的方式
    
> 方法

    · 智能体（推荐系统）利用历史信息进行学习，初始化网络
    · 进行一段时间的服务并积累反馈，进行微更新
    · 更长的一段时间后，进行主更新（利用最新所有的历史数据进行训练）
 
> 微更新

    · 利用用户反馈进行更新。但这里并不是重新训练整个网络。而是用随机扰动更新模型参数，并用用户反馈挑选新旧模型
    · 线上实现起来工程难度较大
    

# 如何如处理序列预测
> 思路

    · 挖掘常见pattern
    · 基于马尔科夫链
    · 循环网络
    · attention
    
# <h4 id="4">第四章：embedding技术在推荐系统中的应用</h4>

> 什么是embedding

    · 用一个低维稠密向量表示一个对象，同时对象之间的相关性与向量之间距离相关
    · 有大量语料的情况下，能够挖掘出一些通用的知识
    
> Embedding为什么重要

    · 大量的onehot特征不利于稀疏向量的处理
    · embedding本身就包含了许多的信息内容，与矩阵分解得到的隐向量相比，表达能力更强
    · embedding方便进行初筛（比如使用lhs）
    
> Word2Vec

    · 将文本进行embedding的操作。优化目标是conditional prob。这个概率的计算通过词向量的距离softmax进行
    · 负采样是避免大矩阵权重更新的时候更新太多没影响的词汇权重。随机挑选一些更新，概率跟词本身出现频率相关
    
> Item2Vec

    · 类似word2vec，从购买序列中进行建模。但是忽略了word2vec建模使用相近词，而是所有pair物品都可以建模
    · 广义的item2vec可以使用dnn单独对物品和用户进行双塔建模，得到两个embedding
    · 局限性就是只能使用序列行数据进行建模（如句子，行为序列）
    
## GraphEmbedding
用于抽取图结构中节点的embedding。图结构的应用如知识图谱等

> DeepWalk

    · 连接序列embedding和graph embedding的中间方法
    · 通过节点的随机游走构建序列样本进行训练
    · 随机游走的方向由有向图的连接权重决定
    
> Node2Vec

    · 调整随机游走的权重，体现网络的同质性（相邻节点的embedding应该尽可能相似）和结构性（结构上相似的节点embedding相近）
    · 结构性需要bfs，同质性需要dfs
    · 通过设置返回参数q和进出参数q控制表达的倾向性，获取不同的embedding结构
    
> EGES

    · 除了通过用户行为序列对物品构建图，还利用物品本身的属性对其进行知识图谱构建。多个图片可以产生多个embedding
    · 多个embedding可以通过avg pooling融合，也可以通过计算attention加权融合
    · 使用了e^a作为attention权重而不是a。这样避免权重为0，也方便回传
    
## embedding与深度学习推荐

> 预训练

    · 如果将embedding层和最后的deep network一起优化，会有更好的全局效果。但是embeding层从高维到低维参数量巨大
    · embedding层可以不用更新，只用embedding更新后面的网络参数
    
> embedding进行召回

    · youtube推荐系统的方法。求出用户向量和视频向量后直接储存。
    · 用户向量是由用户特征通过网络进行输出得到的。视频向量并不用自己计算，是最后softmax层对应的向量（用户向量对每个视频向量求值，softmax计算权重）
    · 虽然可以直接把向量保存起来查询，但也是O(n)的复杂度
    
> LHS局部敏感哈希

    · k维向量对n个对象遍历, O(kn)复杂度。可以用kd树等方法加快。
    · product quantization: 用一个向量表示聚类中心（等价于kmeans）
    · lhs原理：高维空间像低维空间映射，原本近似的样本在低维也近似，但是原本不近似的有一定概率会近似
    · 通过随机k维向量x对所有高维向量映射，得分在一维空间也近似，可以用来分组
    · 单个桶误差大，可以采用多个哈希函数分桶。and和or对于多桶影响力准确性和召回率，需要平衡
    · 哈希函数的类型：欧氏距离/余弦相似度/曼哈顿距离等等

# <h5 id="5">第五章：多视角审视推荐系统</h5>

> 内容

    · 如何选取处理特征
    · 召回层策略
    · 实时性问题
    · 构建优化目标
    · 改进模型
    · 冷启动
    · 探索与利用
    
## 特征工程

> 原则

    · 数据特征决定了机器学习模型的上限。特征的本质是构建某个行为过程的抽象表达
    · 尽可能地保留环境和用户过程的[所有有用信息]，摒弃[冗余信息]
    · 需要结合业务进行设计
    
> 常用特征

    · 用户行为数据：显性（点赞，评分）+隐性（浏览，评论）。显性重要但数据少
    · 用户关系数据：强关系（好友）+ 弱关系（共同点赞）
    · 属性标签类：用户特征 + 商品特征
    · 内容类星系：大段文字/图/视频，需要自己抽取表达特征，或转成标签
    · 上下文信息：跟时间序列相关
    · 统计特征：如某些指标（ctr）的历史数据
    · 组合信息：现在不太需要手动组合了
    
> 特征处理方法

    · 连续型：归一化，离散化（分桶，避免过过拟合），非线性（更好捕捉非线性）
    · 类别型：onehot编码，转成embedding；multihot向量（如多商品记录，在同一个特征域下），再转embedding
    
## 召回层
目的是为了快速将大量数据筛选出感兴趣的，保证召回率，但不损失速度，这两者需要平衡

> 多路召回

    · 采用不同策略特征模型，分别召回（相当于并行化多领域）
    · 可以采用'热门'，'好友'，'最近流行'，'协同过滤'；采用的特征少，方法简单快速
    · 召回策略与业务目标强相关
 
> 基于embedding

    · 在embedding召回中加入其他策略作为embedding信息，使用类似lhs的技术查询
    · 优势在于评分连续性，不用过多的调超参数（如每一类需要选多少个召回）
    
## 实时性
用户希望实时反馈最新的结果。模型更新周期越快效果越好。

> 特征实时性

    · 特征实时性指的是实时收集更新模型特征，进行预测和推荐
    · 客户端： 立刻反馈用户实时的交互情况，秒级延时。直接在客户端缓存行为，并传给服务器
    · 流计算平台：可以在分钟级小窗口内统计，计算特征并存入库
    · 分布式处理平台：小时级延时，保证全面特征存入后的再次计算
    
> 模型实时性

    · 希望更快的抓住全局层面的新数据模式，发现新的趋势和相关性
    · 全量更新：实时性较差，但样本多，容易找到全局最优
    · 增量更新：每次一个小batch更新，速度快，但容易陷入局部最优，通常几轮过后结合全量的更新
    · 在线学习：每个样本都学习，工程要求较高。
    · 局部更新：比如实时更新后面的输出网络，但是每天更新一次embedding网络
    · 客户端更新：自客户端更新用户的embedding并使用，后期在传回服务器
    
## 优化目标

>  Youtube

    · 用户观看时长为目标。因为商业模式是广告，看得越久广告收入越高
    · 点击率为目标的话更容易出现标题党，预览图劲爆的推荐结果
    
> alibaba

    · CVR: 购买转换率，并不只是点击ctr
    · ESMM: 多目标预测方式
    · 需要产品团队更好的定义目标
    
## 模型改进
没有一种模型是解决所有目标的方案。只有根据业务和数据调整模型才是最重要的。

## 冷启动

> 分类

    · 用户冷启动
    · 物品冷启动
    · 系统冷启动
    
> 基于规则的冷启动

    · 通过热门榜，评分等进行启动
    · 根据用户注册时的简单属性，构建决策树推荐表，冷启动时分类推荐
    · 物品冷启动可以找已存在的相应物品（如聚类方法），进行类似的推荐
    · 需要专家制定策略，符合业务的逻辑
    
> 丰富冷启动过程过的用户和物品特征

    · 如用户的属性，从其他应用得到的用户画像
    · 商品，视频等丰富的特征
    · 引导用户输入一些对商品的喜好特征
    
> 主动学习

    · 获取用户的主动反馈，最大化推荐系统的更新与提升
    · 只是尽快的过渡冷启动的过程
    
## 探索与利用
分发评分好，或者被评价少的物品。不至于让冷启动的物品收不到关注。可以帮助物品冷启动/发掘新兴趣/增加多样性。

> 传统方法

    · 多臂老虎机问题：选择多个未知收益老虎机的组合，获取最大化的收益
    · e-greedy算法：每次以e的概率在所有老虎机中搜索，（1-e）的概率选择收益最大化老虎机。e即为探索的概率。用每次回报更新期望。e的概率是一个进化过程
    · thompson采样算法：以收益为目标每个老虎机建立beta分布，根据每次的结果更新分布参数。每次从所有分布中采样，取获得收益最大的
    · UCB算法： ucb值为mean+sqrt(2log(n)/nj)。会倾向于选择评分高，而且被评价次数少的。探索和利用是一个逐步更新的过程
    · 传统方法数学定义清晰，但没办法引入上下文和用户特征
    · LinUCB: 结合了上下文特征，通过设定隐含向量求解置信区间和评分
    
> 个性化方法

    · 将探索部分用线性模型建模。建模包含了上下文特征。
    · 预测的不确定性越高，得分越高
    · 通过数学推到建立探索部分的得分
    
> 基于模型的方法

    · DRN通过强化学习就是一种探索的方式
    
    

# <h6 id="6">第六章：推荐系统的工程实现</h6>

## 数据流
实时流处理+离线批处理。hdfs+redis的混合存储

## 工程实践
在制约条件下最好的实现系统，做出合理的取舍

# <h7 id="7">第七章：推荐系统的评估</h7>

> 重要性

    · 决定了优化方向是否合理
    · 是与其他团队合作的接口性任务
    · 决定了系统是否符合公司商业目标
    
## 离线评估
不用经过生产环境，没有工程风险，测试时间短

> 方法

    · holdout：有一定随机性
    · k fold
    · 自助法：n次有放回的随机取样，没被抽中的进行验证
    
> 指标

    · 准确率
    · precision/recall：可按照排序的前N挑选. 两个指标互相对抗
    · f-score=2PR/(P+R)。调和平均
    · RMSE: 判定回归模型，容易受outlier影响
    · MAPE：误差归一化
    · 对数损失误差
    
> PR曲线

    · 在不同阈值（N）的情况下pr的变化
    · 曲线下的面积为AUC，面积越大表面整体性能越好
    · 曲线整体下降
    
> ROC曲线

    · 跟假阳性/真阳性相关（真假跟本身性质相关，阴阳跟预测标签相关）。真阳性也叫recall
    · 曲线下的面积也代表的模型性能。当FPR接近0时，希望TPR高
    · 面积另一个概念是：取一正一负两个样本，正样本得分高于负样本的概率
    · 曲线整体上升
    · 线下的AUC跟线上并不一定一致。因为线下使用了所有的样本，并不是按用户单独评判
    · AUC对正负样本不敏感，不需要手动设置阈值。但是AUC信息太笼统，而且只关系正负样本排序，不关系正样本之间本身的顺序
    
> ROC曲线计算AUC

    · 因为ROC代表了预测为阳性。当斜率为45度的曲线时，意味着无论真实0/1，预测概率相等。面积越大时，预测1为T的概率比0为T的概率大。
    · 预测标签为概率时，找出每个截断的概率，求出当下的TPR和FPR，画到图像上
    · 如果按照曲线原本计算来看，比较麻烦，需要每一块单独求面积在求和
    · 用相对概率进行计算
        · 假设所有样本按照预测概率排序（由小到大）.M正N负
        · 对于每个正样本，找到比他小的负样本，求概率（对于第一个有rank1 - M个，第二个有rank2-(M-1)个）
        · 所有正样本大于负样本的个数为rank1+...rankm - (1+...+M)。总共的正负样本样例有MN组
        · AUC = [sum(rank+) - M(1+M)/2] / MN
        · 如果预测值样本一致，重新用平均值的rank排序
        · 如果非rank，可以遍历pos和neg。找到对应的概率值判断
        
> 简单计算AUC
    
    · 非rank，可以遍历pos和neg。找到对应的概率值判断
    ```
    def auc(label, pred):
        pos = [i for i in range(len(label)) if label[i]==1]
        neg = [i for i in range(len(label)) if label[i]==0]
        auc = 0
        for i in pos:
            for j in neg:
                if pred[i] > pred[j]:
                    auc += 1
                elif pred[i] == pred[j]
                    auc += 0.5
        return auc / len(pos)*len(neg)
    ```
    · 当每个pred[i] > pred[j]成立时，面积为1； 当每个pred[i] == pred[j]成立时，面积为0.5
    
> mAP

    · 所有用户的AP值平均
    · AP值通过证样本出的precision进行平均
    
## 动态离线评估（replay）
完全的离线测评可能没有考虑实时性，replay可以更好的模拟线上环境

## 线上测试
占用资源，并且可能影响用户效率
> a/b test

    · 独立性采样，还原线上环境。流量同层之间互斥，层与层之间正交（随机独立）
    · 离线指标篇技术，在线指标偏业务　

> interleaving

    · 不直接分组，而是让用户可以体验到两个组别的不同结果，并根据反馈统计
    · 这种方法速度快效率高，但是只能得出用户对某种算法的偏好。要知道对真实业务数据的提升，还是要abtest