# 深度学习推荐系统
## by 王喆

---
# 目录
#### [1.推荐系统简介](#1)
#### [2.前深度学习时代前的推荐系统](#2)
#### [3.深度学习在推荐系统中的应用](#3)
#### [4.embedding技术在推荐系统中的应用](#3)

---

### 代码块
```name
l = []                      ## Initial a empty list
```

# <h2 id="1">第一章：推荐系统简介</h2>

### 问题及总结
> 推荐系统在解决什么问题

	用户角度：如何解决信息过载问题，让用户高效获取感兴趣的信息（与搜索系统相对应）
	公司角度：如何更大限度的吸引用户，提升使用时间，提升转化率，从而达到公司商业目标
	两个方向的目标通常来说是一致有共性的。
    
    推荐系统处理的是人(U)在特定场景(C)下与信息(I)之间的关系 -> F(U, C, I)

>  推荐系统基本架构

	数据部分：
		1. "客户端实时数据处理"， "流平台准实时数据处理"， "离线数据处理"
		2. 样本数据供算法使用；数据生成特征；生成系统监控，商业统计数据
	模型部分：
		1. 召回层：高效从海量数据中找到用户感兴趣的
		2. 排序层：通过精排对初筛结果进行排序
		3. 策略层：通过多样性/新鲜性/流行性等指标进行调整
		4. 离线评估与在线a/b test的存在
		5. 离线训练与在线更新

> 深度学习的贡献

	· 对数据的强拟合能力，对特征组合的强挖掘能力
	· 模型的灵活性能适应不同的应用场景和业务数据

---

# <h2 id="2">第二章：前深度学习时代前的推荐系统</h2>

### 协同过滤 CF
> 传统方法的优势

	· 可解释性强
	· 硬件要求低
	· 易于快速训练和部署

> 皮尔森相关系数

	· 对余弦相似度的补充，如果两个向量取值scale不一样，先减去均值(人对所有物品的均值），去除人的评分偏置的影响
	· 也可以减去物品的评分均值，去除物品偏置的影响
	· 含义就是大家对更好的/更坏的判断是一致的
	· 但是似乎相似性未解决真实的评分问题，如(4.1, 4.2 ,4.3)与(0.1, 0.2, 0.3)是强相关的，但是对新物品评分的预测仍需考虑本身的偏置问题。
	即相似性是相对的，但是评分是绝对的。

> UserCF的缺点

	1. 互联网场景下，用户数量通常远大于物品数，保存用户相似度信息有极大的存储开销（ O(n^2) )
	2. 用户数据向量往往是稀疏向量，导致低频场景下不太适用（用户本身评价少，就不好评价新的物品）

> UserCF和ItemCF的使用场景

	1. UserCF更适用于新闻推荐，具备社交特性。用于发现热点，而不是总是看到相关的新闻
	2. ItemCF更适用于更稳定一点的推荐场景，如购物/观影。用户总喜欢看到相同类型的推荐
	3. ItemCF倾向于找相同的类型的物品, UserCF倾向于根据人的相似推荐各种不同的东西

> 协同过滤的缺点

	1. 更偏向于热门物品，对稀疏向量的处理不好（热门物品容易对其他的物品相似度高，总是在推荐热门物品）
	2. 无法建模用户特征/物体特征，仅仅用到了用户与物品的交互，泛化性较弱。

### 矩阵分解

使用隐向量建模用户和物品，增加模型的泛化性。

> 如何构建人和物品的隐向量
    
    · 人和物品的共现矩阵为 n x m, 分解为 (n x k) 和 (m x k)两个矩阵相乘的形式， k即为隐向量的长度。
    · k的取值与模型的泛化性+计算开销相关，实际工程中需要平衡
    · 这里的隐向量也只建模了人对物品的评分，没有其他信息
    · 需要求解人对物品的新的评价时，只需要将两个k维向量点积即可
    
> 如何分解矩阵 
    
    · 奇异值分解 （SVD）：用于分解非方形矩阵。
    · M = UZV'. Z为对焦矩阵，记录了奇异值大小
    · 取奇异值最大的k为，分别去UV取前面的k个向量即可
    
> SVD缺陷

    1. SVD要求共现矩阵是稠密的，否则需要对矩阵进行填充
    2. 计算复杂度高达O(mn^2)，不适合互联网的大量数据进行计算
    
> 通过梯度下降获取隐向量

    1. 构建目标函数为用户评分与隐函数点积的差平方，使用梯度下降计算，并且可以加上正则化
    2. min[sum(r_ui - q_i · p_u)^2 + lambda(||q_i||^2 + ||p_u||^2)], 优化的复杂度变为O(mnk)
    3. 正则化目的：使模型权重变小，因此波动性变小，但是损失函数尽可能不受影响
    
> 为什么矩阵分解泛化性好

    · CF算法都是只用了user或者item的向量进行计算，但是矩阵分解是通过优化全局的最优进行的，因为同时用到了用于和物品的信息
    
> 如何消除用户本身对物品打分的偏差

    · 加上偏差系数: r_ui = mu + b_i + b_u + q_i · p_u
    · mu为全局系数，b_i为物品偏差，b_u为用户偏差
    
> 协同过滤的优劣

    · 优势：
        1. 泛化能力强，同时建模了用户物品之间的关联性
        2. 不需要储存O(m^2)或者O(n^2)的向量，只需要O[(m+n)*k]， 降低了一个数量级
        3. 获取的隐向量即为embedding，容易和深度学习相组合
    · 局限性：
        1.并没有加入物品，用户，上下文本身的信息特征，

### 逻辑回归

协同过滤和矩阵分解都是用用户物品矩阵的相似度进行建模，并没有加入别的特征信息。逻辑回归通过将样本进行分类，预测正样本的概率。

> 怎么建模
    
    · 将用户和物品的各种信息当作特征向量x, 与w做点积，进行sigmoid打分(f(x)=1 / (1+e^-(wx+b))).
    · wx的值越大, 得到的概率就越接近1
    
> 如何优化

    · 通过概率建模, p(y|x, w) = (fw(x))^y * (1-fw(x))^(1-y)。sigmoid建模为softmax的二类形式
    · 根据极大似然, 所有样本的概率最大化为Mul(p(y|x,w)) 对所有样本, 取对数并对w求导更新w
    · sigmoid函数求导为 f'(z) = f(z)*(1-f(z))*z
    · 求导的推导可以看这里, https://zhuanlan.zhihu.com/p/46928319. 梯度为(x(fw(x)-y))对所有样本取平均
    
> logit回归优势

    1. 数学假设符合伯努利公式,可以做二分类的假设
    2. 基本形式是各种特征的加权和, 符合人类的认知, 可解释性强
    
> 局限性

    1. 模型太简单, 无法更有效地进行特征融合, 损失了很多有用的信息
    
> 数据处理与实现方式

    · sparse feature通过embedding(hidden=1，相当于一个linear层)得到d1个sparse结果，然后求和
    · dense feature通过一个linear层计算wx，相当于weighted sum of dense feature
    · 两个结果加起来就是所有的feature的weighted sum，可以当作sigmoid之前的输出

## 特征组合
单一的特征无法会造成信息的损失。

> ploy2通过暴力组合特征加入两两之间的特征交叉，缺点为
    
    1. 原本稀疏的x现在变成了更加稀疏的组合xixj
    2. 权重参数从n个升级为n^2个
    
>  FM模型
    
    · 与poly2相比，权重不再是wij，而是两个权重的内积<wi, wj>, 相当于为每个特征学习了隐权重向量，数量从O(n^2) 降到了O(nk)
    · 更好的应对了数据稀疏性问题，因为现在隐函数在任意的样本下都可以学习了
    · 具体算法实现可看 https://www.jianshu.com/p/bb2bce9135e4
    
> FM升级到FFM

    · 引入了特征域感知。每个特征的隐权重向量不是单一个向量，而是一个向量组，当特征与另一个特征相结合时，选取对应的权重向量（有一点像attention）
    · 复杂度提升为O(kn^2), 因为每个特征组里都有n个向量选择
    · 复杂度提升之后最多也只能做2阶交叉
    
> GBDT+LR

    · 利用GBDT构建特征，再用LR进行CTR估计
    · GBDT: 梯度提升决策树，XGBoost为优化的常用库
    · 将所有决策树叶子节点组成的特征向量组合起来的到最后的特征。
    · 特征组合能力强劲，而且计算量小，但是训练时间长。但是GBDT容易过拟合，并且丢失了数值特征（只有decision判断了）
    · 从此以后特征工程可以单独进行，只要将得到的特征进行分类即可
    
---

# <h3 id="3">第三章：深度学习在推荐系统中的应用</h3>
可以参考https://github.com/shenweichen/DeepCTR-Torch，查看数据的处理以及实现

> 深度学习优势

    · 表达能力更强，更能挖掘数据
    · 模型灵活，容易对业务应用调整
    
> 演化方向
     
    1）改变网络复杂程度
    2) 改变特征交叉方式
    3) 组合模型
    4) FM模型的演化
    5) 注意力机制的应用
    6）序列模型的使用
    7）强化学习的使用
    
## AutoRec
一个自编码器（两层mlp），从m维向量到k维再到m维，用输入监督输出，中间的k维用作降维特征。由于输出损失存在，模型起到泛化作用。模型可以对缺失值进行填补。

加入正则化更好的避免过拟合。

> User-based和Item-based的区别

    · User-Based每个编码了一个用户对所有物品的评分，只需要forward一次用户向量就知道对所有物品的评分了
    · 但是用户向量是稀疏的，影响到了模型效果

# 特征交叉方法的探索

## Deep Crossing

> 方法

    · embedding层将稀疏特征转换为稠密特征（通过fc层，相当于查表）
    · stacking层将所有的特征拼接在一起
    · multi res layer：多层残差网络将特征进行充分的融合
    · scoring层通过softmax求解目标的概率（比如ctr）

> 历史意义

    · 从当时的角度看，充分的进行了特征的混合，没有手动进行特征交叉了（虽然是把特征拼起来，让resnet去做交叉，没有显式交叉）

## NeuralCF
深度学习的协同过滤模型。

> 方法

    · 将用户向量和物品向量通过fc层得到隐向量，并用隐向量点积得到得分，用sample进行优化
    · 将内积用多层神经网络替换进行输出，能让特征更加充分的混合
    · 可以同时将矩阵分解得到的隐向量一起融入进去

> 优劣

    · 更好的做了信息的交叉，更加灵活的进行了模型组合
    · 没有假如其他的context信息等，仍然是矩阵分解的套路

## PNN

> 方法

    · 相比与deep crossing，将stacking层改成了多个特征的组合拼接（内积外积），更早的进行了特征组合
    · PNN的外积池话实际上是使用了avg pooling后进行外积，损失信息
    
> 优劣

    · 使用了更多的特征，并且强调了主动的特征交叉，让模型更容易捕捉
    · 无差别的特征交叉可能容易损失有价值的信息
    
    
## Wide&Deep
Wide是单层模型，具有记忆能力；Deep是多层模型，具有泛化能力。记忆能力指的是看到相关的特征就输出相近似的结果，单层网络有这样的效果。
多层网络由于做了更多的特征组合，更好的泛化了预测。模型开创了不同网络融合的思路。

> 方法

    · 一部分的特征输入wide单层网络，一部分输入deep多层网络。因此如何选择特征输入的位置是关键
    · wide的部分输入的是直接与结果强相关的特征，充分利用网络的记忆能力；deep部分则是把所有的特征都输入，充分的挖掘相关性
    · wide的输入特征使用了交叉积变化，也包含了特征组合
    · 对两个网络实际上使用了不同的优化器，期望wide网络更稀疏，容易部署
    · deep网络可以理解为deep crossing
    
    
> 数据处理与实现方式

    - wide网络（相当于lr）
    · sparse feature通过embedding(hidden=1，相当于一个linear层)得到d1个sparse结果，然后求和
    · dense feature通过一个linear层计算wx，相当于weighted sum of dense feature
    · 两个结果加起来就是所有的feature的weighted sum，可以当作sigmoid之前的输出
    
    - deep网络（相当于deep crossing）
    · 将sparse feature映射成多维。与dense一起拼接起来，整体输入一个多层linear
    
    - 两个网络的logit输出相加，当作最后结果sigmoid的输入。看实现来说最后是没有加bias的
    
    
## Deep&Cross(DCN)

> 方法

    · 用cross网络替代wide网络，提升特征的交互力度。多个交叉层，每个输入都会与原向量x0。
    · Deep网络更新成cross之后，抛弃了原来的多层mlp的结构，更加主动的进行了信息的融合（比如xix0的外积），使cross网络的表达能力更强
    · 相当避免了deep&wide中的人工挑选特征

# 将FM融入网络结构
FM的特征交叉方式是一种高效的特征组合方式。

## FNN

>  要解决的问题
    
    · 隐含层参数量极大，难以收敛（仅有非零特征的权重被更新）
    · FNN将随即初始化的embedding用FM模型训练好的结果进行初始化。具体操作实际上是让隐权重向量v去初始化embedding层的连接权重（而不是结果）
    · 为特征预训练提供了思路
    · 但只是用来初始化，并没有主动加入特征的组合
    
    
## DeepFM

> 方法

    · 用FM替换了deep & wide中的wide网络（fm中实际上有一层linear，再加上两两乘积和），和dcn一致。但是使用的是fm网络进行替换
    · 输入fm和deep网络中的embedding现在是一样的了
    
    
## NFM

> 方法

    · wide网络保持简单linear，将deep网络替换为fm网络
    · 用神经网络将FM的二阶特征交叉替换掉，争取更高阶的特征交叉形式，是对sparse的feature进行特征的交叉
    · 特征交叉池化层。为了求xixj的和，可以用0.5*(sqrt_of_sum - sum_of_sqrt) = 0.5[(x1+..+xn)^2 - (x1^2+...+xn^2)]的和
    
> 与deepFM的区别是

    · deepFM是吧deep网络和fm网络分开，一个学二阶，一个学更高阶，但是deep网络的输入组合不够明显；
    而这里是把deep接在bi-interaction-pool后面（这个层近似FM层但是不求和），把交叉的特征更深入。
    · 有点像更加强的PNN，结构比较类似
    
    
    
# 注意力机制的使用
## AFM

    · 在特征层和输出层之间加上一个注意力网络，将一个权重联系到特征上去作为注意力得分。
    · 将所有的交叉特征结果用softmax得到注意力得分，与交叉特征加权得到新特征。当attention不存在时，即为nfm网络
    
## DIN
基于电商推荐业务设计的模型

> 方法

    · 用户特征（比如浏览的商品）和商品特征有极强的关联性，直接把特征都扔进网络太简单
    · 利用历史浏览商品和推荐商品求出注意力权重，对对应的历史商品特征进行加权
    · 原来的用户商品特征是所有商品embedding的直接求和，现在变成了根据推荐商品的加权和。
    · 注意这里的attention使用在特征组的序列里面。而且key和query必须是同类（比如店铺和店铺，物品和物品；并不需要求物品和店铺之间的att）
    · local attention单元是把（key，query， key-query， key*query）一起输入dnn网络，求出一个得分
    
## DIEN
DIN的升级版，背景完全一致。模拟了用户兴趣的‘进化’过程。序列模型+注意力机制

> 方法

    · attention仅仅是对序列中的重要性打分，并没有考虑序列的先后顺序（感觉可以加pos embed），最近的行为应该比久远的行为有更大的影响力
    · 兴趣抽取层：跟序列时间相关的表示，用GRU进行模拟
    · 兴趣进化层：在这一层结合了商品特征，与序列化的用户商品特征进行attention处理。使用GRU的同时加入了attention（AUGRU）。更新隐向量时加入了att
    · 序列化模型增加了上线负担，需要合理优化
    
## DRN
强化学习的引入

> 强化学习相关

    · 几个组成部分：智能体、状态、环境、反馈、行动
    · 智能体基于状态进行行动并推送到环境中。推送结果引起反馈，并更新智能体
    · 是一种在线学习的方式
    
> 方法

    · 智能体（推荐系统）利用历史信息进行学习，初始化网络
    · 进行一段时间的服务并积累反馈，进行微更新
    · 更长的一段时间后，进行主更新（利用最新所有的历史数据进行训练）
 
> 微更新

    · 利用用户反馈进行更新。但这里并不是重新训练整个网络。而是用随机扰动更新模型参数，并用用户反馈挑选新旧模型
    · 线上实现起来工程难度较大
    
# <h4 id="4">第四章：embedding技术在推荐系统中的应用</h4>

> 什么是embedding

    · 用一个低维稠密向量表示一个对象，同时对象之间的相关性与向量之间距离相关
    · 有大量语料的情况下，能够挖掘出一些通用的知识
    
> Embedding为什么重要

    · 大量的onehot特征不利于稀疏向量的处理
    · embedding本身就包含了许多的信息内容，与矩阵分解得到的隐向量相比，表达能力更强
    · embedding方便进行初筛（比如使用lhs）
    
> Word2Vec

    · 将文本进行embedding的操作。优化目标是conditional prob。这个概率的计算通过词向量的距离softmax进行
    · 负采样是避免大矩阵权重更新的时候更新太多没影响的词汇权重。随机挑选一些更新，概率跟词本身出现频率相关
    
> Item2Vec

    · 类似word2vec，从购买序列中进行建模。但是忽略了word2vec建模使用相近词，而是所有pair物品都可以建模
    · 广义的item2vec可以使用dnn单独对物品和用户进行双塔建模，得到两个embedding
    · 局限性就是只能使用序列行数据进行建模（如句子，行为序列）
    
## GraphEmbedding
用于抽取图结构中节点的embedding。图结构的应用如知识图谱等

> DeepWalk

    · 连接序列embedding和graph embedding的中间方法
    · 通过节点的随机游走构建序列样本进行训练
    · 随机游走的方向由有向图的连接权重决定
    
> Node2Vec

    · 调整随机游走的权重，体现网络的同质性（相邻节点的embedding应该尽可能相似）和结构性（结构上相似的节点embedding相近）
    · 结构性需要bfs，同质性需要dfs
    · 通过设置返回参数q和进出参数q控制表达的倾向性，获取不同的embedding结构
    
> EGES

    · 除了通过用户行为序列对物品构建图，还利用物品本身的属性对其进行知识图谱构建。多个图片可以产生多个embedding
    · 多个embedding可以通过avg pooling融合，也可以通过计算attention加权融合
    · 使用了e^a作为attention权重而不是a。这样避免权重为0，也方便回传
    
## embedding与深度学习推荐

> 预训练

    · 如果将embedding层和最后的deep network一起优化，会有更好的全局效果。但是embeding层从高维到低维参数量巨大
    · embedding层可以不用更新，只用embedding更新后面的网络参数
    
> embedding进行召回

    · youtube推荐系统的方法。求出用户向量和视频向量后直接储存。
    · 用户向量是由用户特征通过网络进行输出得到的。视频向量并不用自己计算，是最后softmax层对应的向量（用户向量对每个视频向量求值，softmax计算权重）
    · 虽然可以直接把向量保存起来查询，但也是O(n)的复杂度
    
> LHS局部敏感哈希

    · k维向量对n个对象遍历, O(kn)复杂度。可以用kd树等方法加快
    · lhs原理：高维空间像低维空间映射，原本近似的样本在低维也近似，但是原本不近似的有一定概率会近似
    · 通过随机k维向量x对所有高维向量映射，得分在一维空间也近似，可以用来分组
    · 单个桶误差大，可以采用多个哈希函数分桶。and和or对于多桶影响力准确性和召回率，需要平衡
    · 哈希函数的类型：欧氏距离/余弦相似度/曼哈顿距离等等